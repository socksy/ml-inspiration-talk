<!DOCTYPE html>
<html>
  <head>
    <title>Brief overview of machine learning</title>
    <meta charset="utf-8">
    <style>
    @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
    @import url(https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
    @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

     li p { line-height: 1.25em; }
     .red { color: #fa0000; }
     .large { font-size: 2em; }
     a, a > code {
       color: rgb(249, 38, 114);
       text-decoration: none;
     }
     code {
       background: #e7e8e2;
       border-radius: 5px;
     }
    .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
    G.remark-code-line-highlighted     { background-color: #373832; }
    .inverse {
        background: #272822;
        color: #777872;
        text-shadow: 0 0 20px #333;
    }
    .inverse h1, .inverse h2 {
        color: #f3f3f3;
        line-height: 0.8em;
    }
    body { font-family: 'Droid Serif'; }
    h1, h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        font-weight: normal;
    }
    img {
    display: inline-block;
    margin-left: 20%;
    }
    #slide-classification img {
        max-width: 30%;
        max-height: 10%;
    }
    </style>
  </head>
  <body>
    <textarea id="source">

name: inverse
layout: true
class: center, middle, inverse
---
# A (very) Quick intro to Machine Learning in Clojure

---
layout: false
class: middle

# What is machine Learning?

A subfield in AI with a lot of overlap with computational statistics.

The idea is that you have a bunch of data. Then using magical "machine learning" processes, this data makes an internal model, from which we can produce more data.

---
class: middle

# This is usually split up into two types of learning:

* Unsupervised

* Supervised

* Actually, there's a third, reinforcement learning, but that's kinda like supervised

---
class: middle

# Unsupervised

* Throw a bunch of unprocessed data to some algorithms

* Generally more useful as a first step

* Involves finding patterns in data, e.g. clustering, what data is similar to what

---
class: middle

# Supervised

* This time, the data is labelled

* This can generally be split up into two goals, and thus two types of labelling:

- Classification and Regression

---
name: classification

# Classification:

- Or in other words, putting things in categories

![2D simple SVM categorization](https://upload.wikimedia.org/wikipedia/commons/2/2a/Svm_max_sep_hyperplane_with_margin.png)

- So the data is labelled as one category or another
- Then we give it a new data point and using the model (in this case, the line), we guess what the category is going to be.

---

# Regression:

- Given some data, predict other (usually numerical) data

![Linear Regression](https://upload.wikimedia.org/wikipedia/commons/3/3a/Linear_regression.svg)

- Basic example you've all seen before, X and Y co-ords with a "linear regression" model (the red line)
- Given a new datum point on the X axis, you can predict what will be on the Y axis

---
class: middle

# Ok, so how do we do it?

- Most people in the industry use R, a language based on Scheme (a lisp!) and APL (specializing in matrices and vectors)
- This is good for exploring types of models, but is generally quite slow

---
class: middle

# Speeding it up

- Gold standard is actually this ancient maths library based on Fortran, one of the oldest languages
- This is packaged up for us with various interfaces, the most used in the ML community probably being SciKit Learn, a Python library

- They have this awesome chart pointing you in the right direction for your model use:
[An awesome flowchart](http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)
    
---
class: middle, inverse

# So... uh... Clojure?

* So it depends why you're doing Machine Learning
* In my case, I was doing a project that classified tweets as positive or negative, but in real time
* Using a pretty simple algorithm, called naive bayes. It involves summing, dividing, and multiplying, things easy to do in Clojure!
* Instead of using a library, I rolled my own.

---

# Machine Learning part was simple (though maybe not easy...)

Basically, it's Bayes' Theorem. So `P(A|B) = (P(B|A)P(A))/P(B)`.
* `P(A)` is probability of text being positive or negative ("the **sentiment**")

* `P(B)` is probability of a word **occurring**

  e.g. "damn" is a lot more probable in a negative text
* `P(A|B)` is probability of a **sentiment** when the **word is known**

* `P(B|A)` is probability of a **word** occurring when the **sentiment is known**

---

# Explanation

We want to know probability of the sentiment given a word, so P(A|B) will be calculated for each category.

Also, probability of a word occurring can be regarded as constant, so we can simplify it by removing that.
 * `P(A|B) = (P(B|A)P(A))/P(B)`

Finally, we have a number of words in every Tweet, so for simplification, we'll just sum up the different probabilities.

 
---

# It looked a bit like this:

```clojure
(defn feature-probability
"Given a category and feature, probability the feature is in that category."
[category feature model]
(let [feature-count (or (get (category @model) feature) 
                        0) ;not in hash-map means 0 probability
        total (category-total category model)]
    (/ feature-count total)))

;because of the way this naive bayes works, this isn't strictly a probability of
;as in the case of a percent or out of 1
(defn text-probability
[category text model]
(reduce +
        (map #(let [prob (feature-probability category % model)] 
                (if (or (= 0 prob) (= 1 prob)) 
                    prob 
                    (- (java.lang.Math/log prob))))
            (get-features text))))
```

---
class: middle

# The majority of the code was elsewhere

* Specifically, in the extracting of the features (get-features text), and some helper methods
* Also an implementation for k-fold cross-validation, something that I think is really cool, but we don't have time for.


    </textarea>
    <script src="https://gnab.github.io/remark/downloads/remark-latest.min.js">
    </script>
    <script>
      var slideshow = remark.create({highlightStyle: 'monokai'});
    </script>
  </body>
</html>
